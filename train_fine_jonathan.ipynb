{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tobabccVeCqL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU_vl4tZr9y2"
      },
      "outputs": [],
      "source": [
        "# # From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "\n",
        "# import os.path\n",
        "# import shutil\n",
        "# import urllib.request\n",
        "\n",
        "# import huggingface_hub\n",
        "\n",
        "\n",
        "# class HuBERTManager:\n",
        "#     @staticmethod\n",
        "#     def make_sure_hubert_installed(download_url: str = 'https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960.pt', file_name: str = 'hubert.pt'):\n",
        "#         install_dir = os.path.join('data', 'models', 'hubert')\n",
        "#         if not os.path.isdir(install_dir):\n",
        "#             os.makedirs(install_dir, exist_ok=True)\n",
        "#         install_file = os.path.join(install_dir, file_name)\n",
        "#         if not os.path.isfile(install_file):\n",
        "#             print('Downloading HuBERT base model')\n",
        "#             urllib.request.urlretrieve(download_url, install_file)\n",
        "#             print('Downloaded HuBERT')\n",
        "#         return install_file\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def make_sure_tokenizer_installed(model: str = 'japanese-HuBERT-quantizer_24_epoch.pth', repo: str = 'junwchina/bark-voice-cloning-japanese-HuBERT-quantizer', local_file: str = 'tokenizer.pth'):\n",
        "#         install_dir = os.path.join('data', 'models', 'hubert')\n",
        "#         if not os.path.isdir(install_dir):\n",
        "#             os.makedirs(install_dir, exist_ok=True)\n",
        "#         install_file = os.path.join(install_dir, local_file)\n",
        "#         if not os.path.isfile(install_file):\n",
        "#             print('Downloading HuBERT custom tokenizer')\n",
        "#             huggingface_hub.hf_hub_download(repo, model, local_dir=install_dir, local_dir_use_symlinks=False)\n",
        "#             shutil.move(os.path.join(install_dir, model), install_file)\n",
        "#             print('Downloaded tokenizer')\n",
        "#         return install_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBgQmYSCeTAP",
        "outputId": "852e5cb8-7c15-423c-f3d4-b5ad599801c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pQ20RrgegqB",
        "outputId": "6a5052f4-82fe-498b-a511-6a7784e2967e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bark-with-voice-clone'...\n",
            "remote: Enumerating objects: 559, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 559 (delta 7), reused 15 (delta 5), pack-reused 538\u001b[K\n",
            "Receiving objects: 100% (559/559), 1.45 MiB | 20.62 MiB/s, done.\n",
            "Resolving deltas: 100% (237/237), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/serp-ai/bark-with-voice-clone.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI6K_PYKen_f",
        "outputId": "9018da00-2443-438d-f950-bcfff4146d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bark-with-voice-clone\n"
          ]
        }
      ],
      "source": [
        "%cd /content/bark-with-voice-clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_nk0XHI03gk"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/jonathan-folder/Datasets/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cDnO2lAeli1",
        "outputId": "612ac56e-de9c-48ff-c54a-03e810636b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/bark-with-voice-clone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from suno-bark==0.0.1a0)\n",
            "  Downloading boto3-1.28.63-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from suno-bark==0.0.1a0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funcy (from suno-bark==0.0.1a0)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.11.3)\n",
            "Collecting tokenizers (from suno-bark==0.0.1a0)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.66.1)\n",
            "Collecting transformers (from suno-bark==0.0.1a0)\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.32.0,>=1.31.63 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading botocore-1.31.63-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (2.0.2+cu118)\n",
            "Collecting einops (from encodec->suno-bark==0.0.1a0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.18,>=0.16.4 (from tokenizers->suno-bark==0.0.1a0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->suno-bark==0.0.1a0) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->suno-bark==0.0.1a0) (17.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2.31.0)\n",
            "Collecting safetensors>=0.3.1 (from transformers->suno-bark==0.0.1a0)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.63->boto3->suno-bark==0.0.1a0) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.63->boto3->suno-bark==0.0.1a0) (2.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers->suno-bark==0.0.1a0) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->suno-bark==0.0.1a0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->suno-bark==0.0.1a0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->suno-bark==0.0.1a0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->suno-bark==0.0.1a0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.63->boto3->suno-bark==0.0.1a0) (1.16.0)\n",
            "Building wheels for collected packages: suno-bark, encodec\n",
            "  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=1349661 sha256=072cf3fb1f82109d0affed71817848f108bd07491659a3aec9f7a915e4dd8e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/bc/b0/ebe515845724b20e3254d5b3b6286f031f2a19c644ea0f492e\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=2cdbf6ad6d82cdbd14a4c27931453758eb5265be5f9e857882f6f765743153af\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "Successfully built suno-bark encodec\n",
            "Installing collected packages: funcy, safetensors, jmespath, einops, huggingface_hub, botocore, tokenizers, s3transfer, transformers, boto3, encodec, suno-bark\n",
            "Successfully installed boto3-1.28.63 botocore-1.31.63 einops-0.7.0 encodec-0.1.1 funcy-2.0 huggingface_hub-0.17.3 jmespath-1.0.1 s3transfer-0.7.0 safetensors-0.4.0 suno-bark-0.0.1a0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98T4x9Pmesx6",
        "outputId": "78c475cf-3f88-43d9-b42d-f09e5a2b0584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from encodec) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from encodec) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec) (2.0.2+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from encodec) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->encodec) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->encodec) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->encodec) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->encodec) (1.3.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.17.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.21.4\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (2.0)\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq) (3.0.3)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq) (2023.6.3)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq) (4.66.1)\n",
            "Collecting bitarray (from fairseq)\n",
            "  Downloading bitarray-2.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.5/286.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq) (1.23.5)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq) (17.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11289846 sha256=4ecb543926450da17cb8ac65484782b6cf04458c1245e4b1ffa0cf64badcca9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=50858f59f440b82764ddc914969ebafed8b91ba3a5abb3868b8c1850fcfad668\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.8.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install encodec\n",
        "!pip install accelerate\n",
        "!pip install transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install diffusers\n",
        "!pip install funcy\n",
        "!pip install fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riDI7RprffJE",
        "outputId": "51fbc8de-836f-4707-eef3-4d55e52d66fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (2.0.6)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade urllib3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNm_EO-YeCqQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import math\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import torchaudio\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn.functional as F\n",
        "from encodec.utils import convert_audio\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import set_seed\n",
        "from transformers import BertTokenizer\n",
        "from huggingface_hub import hf_hub_download\n",
        "from packaging import version\n",
        "from diffusers.optimization import get_scheduler\n",
        "\n",
        "from utils.bitsandbytes import BitsAndBytesConfig, importlib_metadata, get_keys_to_not_convert, replace_with_bnb_linear, set_module_quantized_tensor_to_device\n",
        "from utils.lora import convert_linear_layer_to_lora, only_optimize_lora_parameters, convert_lora_to_linear_layer\n",
        "from bark.model import GPTConfig, GPT\n",
        "from bark.model_fine import FineGPT, FineGPTConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqLtkq6NeCqS"
      },
      "source": [
        "# Training Args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKVVmUWME0Iv"
      },
      "outputs": [],
      "source": [
        "# !gdown --folder https://drive.google.com/drive/folders/1Ds6LTeVlG2kuci0xwStRfiEffIicwFlW?usp=sharing...somefileid.. -O /content/datasets --remaining-ok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlGZFEaBRWUI",
        "outputId": "8753e0da-fabc-4373-a10a-1f7f080b9f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-16 10:52:46--  https://huggingface.co/junwchina/bark-voice-cloning-japanese-HuBERT-quantizer/resolve/main/japanese-HuBERT-quantizer_24_epoch.pth\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.102, 13.33.33.110, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ee/5b/ee5b2068e250297a0993f6c3c1cb0763e7789f79a3bf96228362e1168bf1353b/07d162b3b42e8d51276ed6767105bdbc4e0b6c856a81c3f8b510fcafc34d76a6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27japanese-HuBERT-quantizer_24_epoch.pth%3B+filename%3D%22japanese-HuBERT-quantizer_24_epoch.pth%22%3B&Expires=1697712766&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NzcxMjc2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lZS81Yi9lZTViMjA2OGUyNTAyOTdhMDk5M2Y2YzNjMWNiMDc2M2U3Nzg5Zjc5YTNiZjk2MjI4MzYyZTExNjhiZjEzNTNiLzA3ZDE2MmIzYjQyZThkNTEyNzZlZDY3NjcxMDViZGJjNGUwYjZjODU2YTgxYzNmOGI1MTBmY2FmYzM0ZDc2YTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=sW31yXKoe7LcYfKE5-jiyAezFa0Mf9nVVv5TrEe5x1e0s-TpfQQwAm%7EPHKOvPyhYPiA1UZBWdeRDTrixa8hxuFORjWfYgQefFoluSFLD1HMyS6Ejfk-zVs-uESbEd-3kBhvNiG9Bmt3IcKxesNDJOQjzsWQMgXB9-1K5bdV9lHZLCERJYDh0qg-HYGXb6On6gVNxj7Up5-o2RxrLPnUVLVI6lKiXMUSXGgMNPyTjE4OBhwe%7E5BXOTtA9MFDPO4QCiM2QSBFIm8K9AeYbv-HqiSBFkkoO%7Egu2MyjmcsHn8iyohTKTVA4Lx2dI8RNeBhmk0smci6w2chBB6G5mgbEQ4A__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-10-16 10:52:46--  https://cdn-lfs.huggingface.co/repos/ee/5b/ee5b2068e250297a0993f6c3c1cb0763e7789f79a3bf96228362e1168bf1353b/07d162b3b42e8d51276ed6767105bdbc4e0b6c856a81c3f8b510fcafc34d76a6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27japanese-HuBERT-quantizer_24_epoch.pth%3B+filename%3D%22japanese-HuBERT-quantizer_24_epoch.pth%22%3B&Expires=1697712766&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NzcxMjc2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lZS81Yi9lZTViMjA2OGUyNTAyOTdhMDk5M2Y2YzNjMWNiMDc2M2U3Nzg5Zjc5YTNiZjk2MjI4MzYyZTExNjhiZjEzNTNiLzA3ZDE2MmIzYjQyZThkNTEyNzZlZDY3NjcxMDViZGJjNGUwYjZjODU2YTgxYzNmOGI1MTBmY2FmYzM0ZDc2YTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=sW31yXKoe7LcYfKE5-jiyAezFa0Mf9nVVv5TrEe5x1e0s-TpfQQwAm%7EPHKOvPyhYPiA1UZBWdeRDTrixa8hxuFORjWfYgQefFoluSFLD1HMyS6Ejfk-zVs-uESbEd-3kBhvNiG9Bmt3IcKxesNDJOQjzsWQMgXB9-1K5bdV9lHZLCERJYDh0qg-HYGXb6On6gVNxj7Up5-o2RxrLPnUVLVI6lKiXMUSXGgMNPyTjE4OBhwe%7E5BXOTtA9MFDPO4QCiM2QSBFIm8K9AeYbv-HqiSBFkkoO%7Egu2MyjmcsHn8iyohTKTVA4Lx2dI8RNeBhmk0smci6w2chBB6G5mgbEQ4A__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.98, 18.155.68.73, 18.155.68.128, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 243656476 (232M) [application/zip]\n",
            "Saving to: ‘japanese-HuBERT-quantizer_24_epoch.pth’\n",
            "\n",
            "japanese-HuBERT-qua 100%[===================>] 232.37M   275MB/s    in 0.8s    \n",
            "\n",
            "2023-10-16 10:52:47 (275 MB/s) - ‘japanese-HuBERT-quantizer_24_epoch.pth’ saved [243656476/243656476]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/junwchina/bark-voice-cloning-japanese-HuBERT-quantizer/resolve/main/japanese-HuBERT-quantizer_24_epoch.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W__lByjCeCqT"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 4\n",
        "eval_batch_size = 4\n",
        "grad_accum = 2\n",
        "ckpt_path = 'models/fine_2.pt'\n",
        "model_type = \"fine\"\n",
        "dataset_path = '/content/drive/Shareddrives/AIR PH/RVC/jonathan-folder/OCT11/preprocess/'\n",
        "\n",
        "project_dir = 'logs/'\n",
        "log_with = 'wandb'\n",
        "hubert_path = 'data/models/hubert/hubert.pt'\n",
        "hubert_tokenizer_path = '/content/bark-with-voice-clone/japanese-HuBERT-quantizer_24_epoch.pth'\n",
        "\n",
        "output_dir = 'fine_output/'\n",
        "resume_from_checkpoint = None\n",
        "\n",
        "checkpointing_steps = 1000\n",
        "\n",
        "mixed_precision = 'fp16'\n",
        "bits = 16 #4 4 and 8 bit are a work in progress\n",
        "compute_dtype = torch.bfloat16\n",
        "double_quant = True\n",
        "quant_type = 'nf4'\n",
        "\n",
        "lora_dim = 64\n",
        "lora_scaling = 1\n",
        "lora_dropout = 0.1\n",
        "lora_module_name = 'transformer.h'\n",
        "optimize_lora_params_only = False\n",
        "\n",
        "learning_rate = 1e-4\n",
        "scale_lr = False\n",
        "use_8bit_adam = False\n",
        "adam_beta1 = 0.9\n",
        "adam_beta2 = 0.999\n",
        "adam_epsilon = 1e-8\n",
        "weight_decay = 0.01\n",
        "\n",
        "llm_int8_skip_modules = None\n",
        "keep_in_fp32_modules = ['lm_head']\n",
        "\n",
        "lr_scheduler_type = 'linear'\n",
        "lr_warmup_steps = 60\n",
        "num_train_epochs = 10\n",
        "max_train_steps = None\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "seed = 741"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTYhejgfeCqT"
      },
      "source": [
        "# Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJXnL4BgeCqU",
        "outputId": "36204203-090a-4b36-f032-c5b0b18b0889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:382: UserWarning: `log_with=wandb` was passed but no supported trackers are currently installed.\n",
            "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n"
          ]
        }
      ],
      "source": [
        "CONTEXT_WINDOW_SIZE = 1024\n",
        "\n",
        "MAX_SEMANTIC_LEN = 256\n",
        "\n",
        "SEMANTIC_RATE_HZ = 49.9\n",
        "SEMANTIC_VOCAB_SIZE = 10_000\n",
        "\n",
        "TEXT_ENCODING_OFFSET = 10_048\n",
        "SEMANTIC_PAD_TOKEN = 10_000\n",
        "TEXT_PAD_TOKEN = 129_595\n",
        "SEMANTIC_INFER_TOKEN = 129_599\n",
        "\n",
        "MAX_COARSE_LEN = 768\n",
        "\n",
        "SAMPLE_RATE = 24_000\n",
        "CHANNELS = 1\n",
        "\n",
        "COARSE_SEMANTIC_PAD_TOKEN = 12_048\n",
        "COARSE_INFER_TOKEN = 12_050\n",
        "\n",
        "CODEBOOK_SIZE = 1024\n",
        "N_COARSE_CODEBOOKS = 2\n",
        "N_FINE_CODEBOOKS = 8\n",
        "COARSE_RATE_HZ = 75\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "USE_SMALL_MODELS = os.environ.get(\"SERP_USE_SMALL_MODELS\", False)\n",
        "\n",
        "default_cache_dir = os.path.join(os.path.expanduser(\"~\"), \".cache\")\n",
        "CACHE_DIR = os.path.join(os.getenv(\"XDG_CACHE_HOME\", default_cache_dir), \"serp\", \"bark_v0\")\n",
        "\n",
        "\n",
        "def _clear_cuda_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "\n",
        "def _md5(fname):\n",
        "    hash_md5 = hashlib.md5()\n",
        "    with open(fname, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()\n",
        "\n",
        "\n",
        "def _download(from_hf_path, file_name, to_local_path):\n",
        "    to_local_path = to_local_path.replace(\"\\\\\", \"/\")\n",
        "    path = '/'.join(to_local_path.split(\"/\")[:-1])\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    hf_hub_download(repo_id=from_hf_path, filename=file_name, local_dir=path)\n",
        "    os.replace(os.path.join(path, file_name), to_local_path)\n",
        "\n",
        "\n",
        "def _tokenize(tokenizer, text):\n",
        "    return tokenizer.encode(text, add_special_tokens=False)\n",
        "\n",
        "\n",
        "def _detokenize(tokenizer, enc_text):\n",
        "    return tokenizer.decode(enc_text)\n",
        "\n",
        "\n",
        "def _normalize_whitespace(text):\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "\n",
        "REMOTE_MODEL_PATHS = {\n",
        "    \"text_small\": {\n",
        "        \"repo_id\": \"suno/bark\",\n",
        "        \"file_name\": \"text.pt\",\n",
        "        \"checksum\": \"b3e42bcbab23b688355cd44128c4cdd3\",\n",
        "    },\n",
        "    \"coarse_small\": {\n",
        "        \"repo_id\": \"suno/bark\",\n",
        "        \"file_name\": \"coarse.pt\",\n",
        "        \"checksum\": \"5fe964825e3b0321f9d5f3857b89194d\",\n",
        "    },\n",
        "    \"fine_small\": {\n",
        "        \"repo_id\": \"suno/bark\",\n",
        "        \"file_name\": \"fine.pt\",\n",
        "        \"checksum\": \"5428d1befe05be2ba32195496e58dc90\",\n",
        "    },\n",
        "    \"text\": {\n",
        "        \"repo_id\": \"suno/bark\",\n",
        "        \"file_name\": \"text_2.pt\",\n",
        "        \"checksum\": \"54afa89d65e318d4f5f80e8e8799026a\",\n",
        "    },\n",
        "    \"coarse\": {\n",
        "        \"repo_id\": \"suno/bark\",\n",
        "        \"file_name\": \"coarse_2.pt\",\n",
        "        \"checksum\": \"8a98094e5e3a255a5c9c0ab7efe8fd28\",\n",
        "    },\n",
        "    \"fine\": {\n",
        "        \"repo_id\": \"suno/bark\",\n",
        "        \"file_name\": \"fine_2.pt\",\n",
        "        \"checksum\": \"59d184ed44e3650774a2f0503a48a97b\",\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def _load_model(ckpt_path, device, use_small=False, model_type=\"text\"):\n",
        "    if model_type == \"text\":\n",
        "        ConfigClass = GPTConfig\n",
        "        ModelClass = GPT\n",
        "    elif model_type == \"coarse\":\n",
        "        ConfigClass = GPTConfig\n",
        "        ModelClass = GPT\n",
        "    elif model_type == \"fine\":\n",
        "        ConfigClass = FineGPTConfig\n",
        "        ModelClass = FineGPT\n",
        "    else:\n",
        "        raise NotImplementedError()\n",
        "    model_key = f\"{model_type}_small\" if use_small or USE_SMALL_MODELS else model_type\n",
        "    model_info = REMOTE_MODEL_PATHS[model_key]\n",
        "    if ckpt_path in [None, '']:\n",
        "        ckpt_path = os.path.join(CACHE_DIR, model_info[\"file_name\"])\n",
        "    if not os.path.exists(ckpt_path):\n",
        "        logger.info(f\"{model_type} model not found, downloading into `{CACHE_DIR}`.\")\n",
        "        _download(model_info[\"repo_id\"], model_info[\"file_name\"], ckpt_path)\n",
        "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "    # this is a hack\n",
        "    model_args = checkpoint[\"model_args\"]\n",
        "    if \"input_vocab_size\" not in model_args:\n",
        "        model_args[\"input_vocab_size\"] = model_args[\"vocab_size\"]\n",
        "        model_args[\"output_vocab_size\"] = model_args[\"vocab_size\"]\n",
        "        del model_args[\"vocab_size\"]\n",
        "    gptconf = ConfigClass(**checkpoint[\"model_args\"])\n",
        "    model = ModelClass(gptconf)\n",
        "    state_dict = checkpoint[\"model\"]\n",
        "    # fixup checkpoint\n",
        "    unwanted_prefix = \"_orig_mod.\"\n",
        "    for k, v in list(state_dict.items()):\n",
        "        if k.startswith(unwanted_prefix):\n",
        "            state_dict[k[len(unwanted_prefix) :]] = state_dict.pop(k)\n",
        "    extra_keys = set(state_dict.keys()) - set(model.state_dict().keys())\n",
        "    extra_keys = set([k for k in extra_keys if not k.endswith(\".attn.bias\")])\n",
        "    missing_keys = set(model.state_dict().keys()) - set(state_dict.keys())\n",
        "    missing_keys = set([k for k in missing_keys if not k.endswith(\".attn.bias\")])\n",
        "    if len(extra_keys) != 0:\n",
        "        raise ValueError(f\"extra keys found: {extra_keys}\")\n",
        "    if len(missing_keys) != 0:\n",
        "        raise ValueError(f\"missing keys: {missing_keys}\")\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    n_params = model.get_num_params()\n",
        "    val_loss = checkpoint[\"best_val_loss\"].item()\n",
        "    print(f\"Loaded {model_type} model with {n_params} params, val_loss={val_loss:.4f}.\")\n",
        "    del checkpoint, state_dict\n",
        "    _clear_cuda_cache()\n",
        "    if model_type == \"text\":\n",
        "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "        # tokenizer = BertTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
        "        return model, tokenizer\n",
        "    return model\n",
        "\n",
        "\n",
        "def _flatten_codebooks(arr, offset_size=CODEBOOK_SIZE):\n",
        "    assert len(arr.shape) == 2\n",
        "    arr = arr.copy()\n",
        "    if offset_size is not None:\n",
        "        for n in range(1, arr.shape[0]):\n",
        "            arr[n, :] += offset_size * n\n",
        "    flat_arr = arr.ravel(\"F\")\n",
        "    return flat_arr\n",
        "\n",
        "\n",
        "def load_filepaths_and_text(filename, split=\"|\"):\n",
        "    with open(filename, encoding='utf-8', errors='ignore') as f:\n",
        "        filepaths_and_text = [line.strip().split(split) for line in f]\n",
        "        base = os.path.dirname(filename)\n",
        "        for j in range(len(filepaths_and_text)):\n",
        "            filepaths_and_text[j][0] = os.path.join(base, filepaths_and_text[j][0])\n",
        "    return filepaths_and_text\n",
        "\n",
        "\n",
        "class TtsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, opt):\n",
        "        self.path = os.path.dirname(opt['path'])\n",
        "        self.mode = opt['mode']\n",
        "        self.audiopaths_and_text = load_filepaths_and_text(os.path.join(opt['path'] , opt['mode'] + '.txt'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audiopath_and_text = self.audiopaths_and_text[index]\n",
        "        audiopath = audiopath_and_text[0]\n",
        "\n",
        "        tokens = np.load(audiopath.replace('.wav', '.npz').replace('wavs', 'tokens'))\n",
        "        fine_tokens = tokens['fine']\n",
        "\n",
        "        return torch.from_numpy(fine_tokens)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audiopaths_and_text)\n",
        "\n",
        "\n",
        "class TtsCollater():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def __call__(self, batch):\n",
        "        max_len = 1024\n",
        "        fine_tokens = []\n",
        "\n",
        "        for fine_tokens_ in batch:\n",
        "            if fine_tokens_.shape[1] > max_len:\n",
        "                start_idx = np.random.randint(0, fine_tokens_.shape[1] - max_len + 1)\n",
        "                fine_tokens_ = fine_tokens_[:, start_idx : start_idx + max_len]\n",
        "\n",
        "            pad_size = max_len - fine_tokens_.shape[1]\n",
        "            fine_tokens_ = F.pad(fine_tokens_, (0, pad_size), value=CODEBOOK_SIZE)\n",
        "\n",
        "            fine_tokens_ = fine_tokens_.T\n",
        "\n",
        "            fine_tokens.append(fine_tokens_)\n",
        "\n",
        "        return {'fine_tokens': torch.stack(fine_tokens).contiguous()}\n",
        "\n",
        "\n",
        "accelerator = Accelerator(\n",
        "    gradient_accumulation_steps=grad_accum,\n",
        "    mixed_precision=mixed_precision,\n",
        "    log_with=log_with,\n",
        "    project_dir=project_dir,\n",
        ")\n",
        "device = accelerator.device\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVFsb_cNeCqV"
      },
      "source": [
        "# Setup Dataset (only need to do this once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ-CKybJeCqW"
      },
      "outputs": [],
      "source": [
        "# max_duration_sec = 15.12 # the maximum allowed duration in seconds\n",
        "\n",
        "# path = dataset_path\n",
        "\n",
        "# # From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "# from hubert.hubert_manager import HuBERTManager\n",
        "# hubert_manager = HuBERTManager()\n",
        "# from hubert.pre_kmeans_hubert import CustomHubert\n",
        "# from hubert.customtokenizer import CustomTokenizer\n",
        "# hubert_manager.make_sure_hubert_installed()\n",
        "# hubert_manager.make_sure_tokenizer_installed()\n",
        "\n",
        "# # Load the HuBERT model\n",
        "# hubert_model = CustomHubert(checkpoint_path=hubert_path).to(device)\n",
        "# hubert_model.eval()\n",
        "# for param in hubert_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # Load the CustomTokenizer model\n",
        "# hubert_tokenizer = CustomTokenizer.load_from_checkpoint(hubert_tokenizer_path).to(device)  # Automatically uses the right layers\n",
        "\n",
        "# from bark.generation import load_codec_model\n",
        "# codec_model = load_codec_model(use_gpu=True)\n",
        "# codec_model.eval()\n",
        "# for param in codec_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "\n",
        "# def get_duration(wav, sr):\n",
        "#     return wav.shape[1] / sr\n",
        "\n",
        "# valid_lines_train = []\n",
        "# # convert wavs to semantic tokens\n",
        "# for wav_path, txt in load_filepaths_and_text(path + 'train.txt'):\n",
        "#     wav, sr = torchaudio.load(wav_path)\n",
        "#     if not get_duration(wav, sr) > max_duration_sec:\n",
        "#         valid_lines_train.append((wav_path, txt))\n",
        "#     wav = convert_audio(wav, sr, SAMPLE_RATE, CHANNELS).to(device)\n",
        "\n",
        "#     semantic_vectors = hubert_model.forward(wav, input_sample_hz=SAMPLE_RATE)\n",
        "#     semantic_tokens = hubert_tokenizer.get_token(semantic_vectors)\n",
        "\n",
        "#     # save semantic tokens\n",
        "#     os.makedirs(os.path.join(path, 'tokens'), exist_ok=True)\n",
        "#     semantic_tokens = semantic_tokens.cpu().numpy()\n",
        "\n",
        "#     # Extract discrete codes from EnCodec\n",
        "#     with torch.no_grad():\n",
        "#         encoded_frames = codec_model.encode(wav.unsqueeze(0))\n",
        "#     codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]\n",
        "\n",
        "#     # move codes to cpu\n",
        "#     codes = codes.cpu().numpy()\n",
        "\n",
        "#     # save tokens\n",
        "#     np.savez_compressed(os.path.join(path, 'tokens', os.path.basename(wav_path).replace('.wav', '.npz')), fine=codes, coarse=codes[:2, :], semantic=semantic_tokens)\n",
        "\n",
        "# # rewrite train.txt with valid lines\n",
        "# with open(path + 'train_valid.txt', 'w', encoding='utf-8') as f:\n",
        "#     for wav_path, txt in valid_lines_train:\n",
        "#         wav_path = os.path.relpath(wav_path, dataset_path).replace('\\\\', '/')\n",
        "#         f.write(f'{wav_path}|{txt}\\n')\n",
        "\n",
        "# valid_lines_valid = []\n",
        "# for wav_path, txt in load_filepaths_and_text(path + 'valid.txt'):\n",
        "#     wav, sr = torchaudio.load(wav_path)\n",
        "#     if not get_duration(wav, sr) > max_duration_sec:\n",
        "#         valid_lines_valid.append((wav_path, txt))\n",
        "#     wav = convert_audio(wav, sr, SAMPLE_RATE, CHANNELS).to(device)\n",
        "\n",
        "#     semantic_vectors = hubert_model.forward(wav, input_sample_hz=SAMPLE_RATE)\n",
        "#     semantic_tokens = hubert_tokenizer.get_token(semantic_vectors)\n",
        "\n",
        "#     # save semantic tokens\n",
        "#     os.makedirs(os.path.join(path, 'tokens'), exist_ok=True)\n",
        "#     semantic_tokens = semantic_tokens.cpu().numpy()\n",
        "\n",
        "#     # Extract discrete codes from EnCodec\n",
        "#     with torch.no_grad():\n",
        "#         encoded_frames = codec_model.encode(wav.unsqueeze(0))\n",
        "#     codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]\n",
        "\n",
        "#     # move codes to cpu\n",
        "#     codes = codes.cpu().numpy()\n",
        "\n",
        "#     # save tokens\n",
        "#     np.savez_compressed(os.path.join(path, 'tokens', os.path.basename(wav_path).replace('.wav', '.npz')), fine=codes, coarse=codes[:2, :], semantic=semantic_tokens)\n",
        "\n",
        "# # rewrite valid.txt with valid lines\n",
        "# with open(path + 'valid_valid.txt', 'w', encoding='utf-8') as f:\n",
        "#     for wav_path, txt in valid_lines_valid:\n",
        "#         wav_path = os.path.relpath(wav_path, dataset_path).replace('\\\\', '/')\n",
        "#         f.write(f'{wav_path}|{txt}\\n')\n",
        "\n",
        "# del hubert_model\n",
        "# del hubert_tokenizer\n",
        "# del codec_model\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHewcs5LeCqX"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "db93bee9e027491aba19a6030c4c6437",
            "316a25e3d35a45b78bef65e4e07c31b9",
            "f3b7d45339b94f078a89290ac9da5607",
            "b59b37c0ccd24e2ba77cb677242acded",
            "9c666db811c74072956c34b49ab514a0",
            "b9f97ebe7f0a4a8dac082abec53fd2db",
            "fea567cda0fd43469cfcc0cdf8d97a2f",
            "5213e33c1ecc4273b3777ed3fbfe0980",
            "7b5e8e1c227742f4b9ae7a98e0a0f836",
            "abb656d962304aa6b6b1f491c227cb3f",
            "fbb09c187b74426aa46d20f3a7ada9f6"
          ]
        },
        "id": "E90rA-eueCqX",
        "outputId": "f69ddd46-5ba2-435f-e246-e15773f94ab4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading fine_2.pt:   0%|          | 0.00/3.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db93bee9e027491aba19a6030c4c6437"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded fine model with 302090240 params, val_loss=2.0786.\n"
          ]
        }
      ],
      "source": [
        "model = _load_model(ckpt_path, device, use_small=False, model_type=model_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMn0Dpp0eCqY"
      },
      "outputs": [],
      "source": [
        "if scale_lr:\n",
        "    learning_rate = (\n",
        "        learning_rate * grad_accum * train_batch_size * accelerator.num_processes\n",
        "    )\n",
        "\n",
        "if use_8bit_adam:\n",
        "    try:\n",
        "        import bitsandbytes as bnb\n",
        "    except ImportError:\n",
        "        raise ImportError(\n",
        "            \"To use 8-bit Adam, please install the bitsandbytes library: `pip install bitsandbytes`.\"\n",
        "        )\n",
        "\n",
        "    optimizer_class = bnb.optim.AdamW8bit\n",
        "else:\n",
        "    optimizer_class = torch.optim.AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIh1ZpLkeCqY"
      },
      "outputs": [],
      "source": [
        "quantization_config=BitsAndBytesConfig(\n",
        "    load_in_4bit=bits == 4,\n",
        "    load_in_8bit=bits == 8,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=double_quant,\n",
        "    bnb_4bit_quant_type=quant_type # {'fp4', 'nf4'}\n",
        ")\n",
        "\n",
        "# if quantization_config.load_in_8bit or quantization_config.load_in_4bit:\n",
        "#     if quantization_config.load_in_8bit:\n",
        "#         logger.info(\"Detected 8-bit loading: activating 8-bit loading for this model\")\n",
        "#     elif quantization_config.load_in_4bit:\n",
        "#         logger.info(\"Detected 4-bit loading: activating 4-bit loading for this model\")\n",
        "\n",
        "#     # We keep some modules such as the lm_head in their original dtype for numerical stability reasons\n",
        "#     if llm_int8_skip_modules is None or len(llm_int8_skip_modules) == 0:\n",
        "#         modules_to_not_convert = [] # get_keys_to_not_convert(model)\n",
        "#     else:\n",
        "#         modules_to_not_convert = llm_int8_skip_modules\n",
        "\n",
        "#     if not isinstance(modules_to_not_convert, list):\n",
        "#         modules_to_not_convert = [modules_to_not_convert]\n",
        "\n",
        "#     modules_to_not_convert.extend(keep_in_fp32_modules)\n",
        "\n",
        "#     supports_4bit = version.parse(importlib_metadata.version(\"bitsandbytes\")) >= version.parse(\"0.39.0\")\n",
        "\n",
        "#     if quantization_config.load_in_4bit and not supports_4bit:\n",
        "#         raise ValueError(\n",
        "#             \"You have a version of `bitsandbytes` that is not compatible with 4bit inference and training\"\n",
        "#             \" make sure you have the latest version of `bitsandbytes` installed\"\n",
        "#         )\n",
        "\n",
        "#     if len(modules_to_not_convert) == 0:\n",
        "#         modules_to_not_convert = None\n",
        "\n",
        "#     model = replace_with_bnb_linear(\n",
        "#         model, modules_to_not_convert=modules_to_not_convert, quantization_config=quantization_config\n",
        "#     )\n",
        "\n",
        "#     # training in 8-bit is only available in 0.37.0+\n",
        "#     model._is_kbit_training_enabled = version.parse(\n",
        "#         importlib_metadata.version(\"bitsandbytes\")\n",
        "#     ) >= version.parse(\"0.37.0\")\n",
        "\n",
        "#     model.config.quantization_config = quantization_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvo-RhVxeCqY"
      },
      "outputs": [],
      "source": [
        "if bits == 4:\n",
        "    from accelerate.utils import CustomDtype\n",
        "    target_dtype = CustomDtype.INT4\n",
        "elif bits == 8:\n",
        "    target_dtype = torch.int8\n",
        "\n",
        "if lora_dim > 0:\n",
        "    for param in model.parameters():\n",
        "        if param.ndim == 1:\n",
        "            # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
        "            param.data = param.data.to(torch.float32)\n",
        "\n",
        "    class CastOutputToFloat(nn.Sequential):\n",
        "        def forward(self, x):\n",
        "            return super().forward(x).to(torch.float32)\n",
        "\n",
        "    # model.lm_head = CastOutputToFloat(model.lm_head)\n",
        "    for i, lm_head in enumerate(model.lm_heads):\n",
        "        model.lm_heads[i] = CastOutputToFloat(lm_head)\n",
        "\n",
        "    model = convert_linear_layer_to_lora(model, lora_module_name,\n",
        "                                            lora_dim=lora_dim, lora_scaling=lora_scaling,\n",
        "                                            lora_dropout=lora_dropout)\n",
        "    if optimize_lora_params_only:\n",
        "        model = only_optimize_lora_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mRijAuQeCqZ"
      },
      "outputs": [],
      "source": [
        "params_to_optimize = (\n",
        "        param for param in model.parameters() if param.requires_grad\n",
        "    )\n",
        "\n",
        "optimizer = optimizer_class(\n",
        "    params_to_optimize,\n",
        "    lr=learning_rate,\n",
        "    betas=(adam_beta1, adam_beta2),\n",
        "    weight_decay=weight_decay,\n",
        "    eps=adam_epsilon,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K8YkXQCeCqZ"
      },
      "outputs": [],
      "source": [
        "opt_train = {\n",
        "    'path': dataset_path,\n",
        "    'mode': 'train',\n",
        "}\n",
        "\n",
        "opt_val = {\n",
        "    'path': dataset_path,\n",
        "    'mode': 'valid',\n",
        "}\n",
        "\n",
        "train_dataset = TtsDataset(opt_train)\n",
        "validation_dataset = TtsDataset(opt_val)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=train_batch_size,\n",
        "    collate_fn=TtsCollater(),\n",
        ")\n",
        "\n",
        "validation_dataloader = torch.utils.data.DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=eval_batch_size,\n",
        "    collate_fn=TtsCollater(),\n",
        ")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=COARSE_SEMANTIC_PAD_TOKEN)\n",
        "\n",
        "# Scheduler and math around the number of training steps.\n",
        "overrode_max_train_steps = False\n",
        "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / grad_accum)\n",
        "if max_train_steps is None:\n",
        "    max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "    overrode_max_train_steps = True\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    lr_scheduler_type,\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=lr_warmup_steps * grad_accum,\n",
        "    num_training_steps=max_train_steps * grad_accum,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW20W7NPeCqZ"
      },
      "outputs": [],
      "source": [
        "model, optimizer, train_dataloader, validation_dataloader, lr_scheduler = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, validation_dataloader, lr_scheduler\n",
        ")\n",
        "accelerator.register_for_checkpointing(lr_scheduler)\n",
        "\n",
        "weight_dtype = torch.float32\n",
        "if accelerator.mixed_precision == \"fp16\":\n",
        "    weight_dtype = torch.float16\n",
        "elif accelerator.mixed_precision == \"bf16\":\n",
        "    weight_dtype = torch.bfloat16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLdrmaZGeCqa"
      },
      "outputs": [],
      "source": [
        "# We need to recalculate our total training steps as the size of the training dataloader may have changed.\n",
        "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / grad_accum)\n",
        "if overrode_max_train_steps:\n",
        "    max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "# Afterwards we recalculate our number of training epochs\n",
        "num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n",
        "\n",
        "# We need to initialize the trackers we use, and also store our configuration.\n",
        "# The trackers initializes automatically on the main process.\n",
        "if accelerator.is_main_process:\n",
        "    accelerator.init_trackers(\"bark_coarse\", config={})\n",
        "\n",
        "total_batch_size = train_batch_size * accelerator.num_processes * grad_accum\n",
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
        "logger.info(f\"  Num batches each epoch = {len(train_dataloader)}\")\n",
        "logger.info(f\"  Num Epochs = {num_train_epochs}\")\n",
        "logger.info(f\"  Instantaneous batch size per device = {train_batch_size}\")\n",
        "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "logger.info(f\"  Gradient Accumulation steps = {grad_accum}\")\n",
        "logger.info(f\"  Total optimization steps = {max_train_steps}\")\n",
        "global_step = 0\n",
        "first_epoch = 0\n",
        "\n",
        "if resume_from_checkpoint:\n",
        "    if resume_from_checkpoint != \"latest\":\n",
        "        path = os.path.basename(resume_from_checkpoint)\n",
        "    else:\n",
        "        # Get the most recent checkpoint\n",
        "        dirs = os.listdir(output_dir)\n",
        "        dirs = [d for d in dirs if d.startswith(\"checkpoint\")]\n",
        "        dirs = sorted(dirs, key=lambda x: int(x.split(\"-\")[1]))\n",
        "        path = dirs[-1]\n",
        "    accelerator.print(f\"Resuming from checkpoint {path}\")\n",
        "    accelerator.load_state(os.path.join(output_dir, path))\n",
        "    global_step = int(path.split(\"-\")[1])\n",
        "\n",
        "    resume_global_step = global_step * grad_accum\n",
        "    first_epoch = resume_global_step // num_update_steps_per_epoch\n",
        "    resume_step = resume_global_step % num_update_steps_per_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p4mi6JOkeCqa"
      },
      "outputs": [],
      "source": [
        "if accelerator.is_main_process:\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    num_batches = 0\n",
        "    num_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for val_step, val_batch in enumerate(validation_dataloader):\n",
        "            # Similar to training, process the validation batch\n",
        "            fine_targets_7 = val_batch['fine_tokens'][:, :, 6]\n",
        "            fine_tokens_input_7 = torch.cat([val_batch['fine_tokens'][:, :, :6], torch.zeros_like(val_batch['fine_tokens'][:, :, 6:])], dim=2)\n",
        "            fine_targets_8 = val_batch['fine_tokens'][:, :, 7]\n",
        "            fine_tokens_input_8 = torch.cat([val_batch['fine_tokens'][:, :, :7], torch.zeros_like(val_batch['fine_tokens'][:, :, 7:])], dim=2)\n",
        "\n",
        "            # Forward pass for validation\n",
        "            logits_7 = model(6, fine_tokens_input_7)\n",
        "            logits_8 = model(7, fine_tokens_input_8)\n",
        "\n",
        "            # Calculate the validation loss\n",
        "            loss_7 = criterion(logits_7.view(-1, model.config.output_vocab_size), fine_targets_7.view(-1))\n",
        "            loss_8 = criterion(logits_8.view(-1, model.config.output_vocab_size), fine_targets_8.view(-1))\n",
        "\n",
        "            loss = (loss_7 + loss_8) / 2\n",
        "            validation_loss += loss.item()\n",
        "            num_batches += 1\n",
        "            num_samples += val_batch['fine_tokens'].size(0)\n",
        "\n",
        "    average_validation_loss = validation_loss / num_batches\n",
        "    logger.info(f\"Validation Loss: {average_validation_loss} over {num_samples} samples and {num_batches} batches.\")\n",
        "    print(f\"Validation Loss: {average_validation_loss} over {num_samples} samples and {num_batches} batches.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8jJ4ZMKhGqWy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory containing the files\n",
        "directory_path = '/content/drive/Shareddrives/AIR PH/RVC/jonathan-folder/OCT11/preprocess/tokens'\n",
        "\n",
        "# List of all files with the \".npz\" extension\n",
        "file_list = [f for f in os.listdir(directory_path) if f.endswith('.npz')]\n",
        "\n",
        "# Extract the numeric part of the filenames and convert them to integers\n",
        "file_numbers = [int(file.split('.')[0]) for file in file_list]\n",
        "\n",
        "# Sort the list of numbers\n",
        "file_numbers.sort()\n",
        "\n",
        "# Check for skipped numbers\n",
        "skipped_numbers = [str(i) + '.npz' for i in range(file_numbers[0], file_numbers[-1] + 1) if i not in file_numbers]\n",
        "\n",
        "if len(skipped_numbers) == 0:\n",
        "    print(\"No skipped numbers found.\")\n",
        "else:\n",
        "    print(\"Skipped numbers found:\", skipped_numbers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53e3b0-eeCqa"
      },
      "source": [
        "#  Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AoVdIzK5eCqa"
      },
      "outputs": [],
      "source": [
        "# Only show the progress bar once on each machine.\n",
        "progress_bar = tqdm(range(global_step, max_train_steps), disable=not accelerator.is_local_main_process)\n",
        "progress_bar.set_description(\"Steps\")\n",
        "\n",
        "for epoch in range(first_epoch, num_train_epochs):\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Skip steps until we reach the resumed step\n",
        "        if resume_from_checkpoint and epoch == first_epoch and step < resume_step:\n",
        "            if step % grad_accum == 0:\n",
        "                progress_bar.update(1)\n",
        "            continue\n",
        "\n",
        "        with accelerator.accumulate(model):\n",
        "            fine_targets_7 = batch['fine_tokens'][:, :, 6]\n",
        "            fine_tokens_input_7 = torch.cat([batch['fine_tokens'][:, :, :6], torch.zeros_like(batch['fine_tokens'][:, :, 6:])], dim=2)\n",
        "            fine_targets_8 = batch['fine_tokens'][:, :, 7]\n",
        "            fine_tokens_input_8 = torch.cat([batch['fine_tokens'][:, :, :7], torch.zeros_like(batch['fine_tokens'][:, :, 7:])], dim=2)\n",
        "\n",
        "            # Forward pass\n",
        "            logits_7 = model(6, fine_tokens_input_7)\n",
        "            logits_8 = model(7, fine_tokens_input_8)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss_7 = criterion(logits_7.view(-1, model.config.output_vocab_size), fine_targets_7.view(-1))\n",
        "            loss_8 = criterion(logits_8.view(-1, model.config.output_vocab_size), fine_targets_8.view(-1))\n",
        "\n",
        "            loss = (loss_7 + loss_8) / 2\n",
        "\n",
        "            accelerator.backward(loss)\n",
        "            if accelerator.sync_gradients:\n",
        "                params_to_clip = (\n",
        "                    param for param in model.parameters() if param.requires_grad\n",
        "                )\n",
        "                accelerator.clip_grad_norm_(params_to_clip, max_grad_norm)\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Checks if the accelerator has performed an optimization step behind the scenes\n",
        "        if accelerator.sync_gradients:\n",
        "            progress_bar.update(1)\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % checkpointing_steps == 0:\n",
        "                if accelerator.is_main_process:\n",
        "                    save_path = os.path.join(output_dir, f\"checkpoint-{global_step}\")\n",
        "                    accelerator.save_state(save_path)\n",
        "                    logger.info(f\"Saved state to {save_path}\")\n",
        "\n",
        "        logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0]}\n",
        "        progress_bar.set_postfix(**logs)\n",
        "        accelerator.log(logs, step=global_step)\n",
        "\n",
        "        if global_step >= max_train_steps:\n",
        "            break\n",
        "\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "if accelerator.is_main_process:\n",
        "    if lora_dim > 0:\n",
        "        model = convert_lora_to_linear_layer(model)\n",
        "    # save model\n",
        "    accelerator.save(model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
        "\n",
        "    config = model.config.__dict__\n",
        "    # save config\n",
        "    with open(os.path.join(output_dir, \"config.json\"), \"w\") as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "\n",
        "accelerator.end_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPzbOUtaeCqb"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WCGnNRSDeCqb"
      },
      "outputs": [],
      "source": [
        "if accelerator.is_main_process:\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    num_batches = 0\n",
        "    num_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for val_step, val_batch in enumerate(validation_dataloader):\n",
        "            # Similar to training, process the validation batch\n",
        "            fine_targets_7 = val_batch['fine_tokens'][:, :, 6]\n",
        "            fine_tokens_input_7 = torch.cat([val_batch['fine_tokens'][:, :, :6], torch.zeros_like(val_batch['fine_tokens'][:, :, 6:])], dim=2)\n",
        "            fine_targets_8 = val_batch['fine_tokens'][:, :, 7]\n",
        "            fine_tokens_input_8 = torch.cat([val_batch['fine_tokens'][:, :, :7], torch.zeros_like(val_batch['fine_tokens'][:, :, 7:])], dim=2)\n",
        "\n",
        "            # Forward pass for validation\n",
        "            logits_7 = model(6, fine_tokens_input_7)\n",
        "            logits_8 = model(7, fine_tokens_input_8)\n",
        "\n",
        "            # Calculate the validation loss\n",
        "            loss_7 = criterion(logits_7.view(-1, model.config.output_vocab_size), fine_targets_7.view(-1))\n",
        "            loss_8 = criterion(logits_8.view(-1, model.config.output_vocab_size), fine_targets_8.view(-1))\n",
        "\n",
        "            loss = (loss_7 + loss_8) / 2\n",
        "            validation_loss += loss.item()\n",
        "            num_batches += 1\n",
        "            num_samples += val_batch['fine_tokens'].size(0)\n",
        "\n",
        "    average_validation_loss = validation_loss / num_batches\n",
        "    logger.info(f\"Validation Loss: {average_validation_loss} over {num_samples} samples and {num_batches} batches.\")\n",
        "    print(f\"Validation Loss: {average_validation_loss} over {num_samples} samples and {num_batches} batches.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c-0HJk0zLjKh"
      },
      "outputs": [],
      "source": [
        "# !mv \"/content/bark-with-voice-clone/fine_output\" \"/content/drive/MyDrive/jonathan-folder/OCT6/2/epoch_35\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b4dY94y7LjEW"
      },
      "outputs": [],
      "source": [
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nrxpW8cRwc-o"
      },
      "outputs": [],
      "source": [
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gHDW67zahxb2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NJ0f937D9fYw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/bark-with-voice-clone/fine_output\"\n",
        "destination_path = \"/content/drive/Shareddrives/AIR PH/RVC/jonathan-folder/OCT11/preprocess/epoch10\"\n",
        "\n",
        "# Move the file\n",
        "!mv \"$source_path\" \"$destination_path\"\n",
        "\n",
        "# Check if the move operation was successful\n",
        "if os.path.exists(destination_path):\n",
        "    print(\"File moved successfully.\")\n",
        "else:\n",
        "    print(\"File move failed.\")\n",
        "\n",
        "# Define the maximum runtime (in seconds) before disconnecting\n",
        "max_runtime_seconds = 20 * 60  # 20 minutes\n",
        "\n",
        "# Get the current time\n",
        "start_time = time.time()\n",
        "\n",
        "# Check the runtime and disconnect if necessary\n",
        "while True:\n",
        "    current_time = time.time()\n",
        "    elapsed_time_seconds = current_time - start_time\n",
        "\n",
        "    # Disconnect if the file was moved successfully or if the maximum runtime is reached\n",
        "    if os.path.exists(destination_path) or elapsed_time_seconds >= max_runtime_seconds:\n",
        "        print(\"Disconnecting runtime...\")\n",
        "        drive.flush_and_unmount()\n",
        "        os.system(\"pkill -9 -f ipykernel_launcher\")\n",
        "        break\n",
        "\n",
        "    # Sleep for a short duration before checking again\n",
        "    time.sleep(60)  # Check every minute\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IgN6Rr0dWOF9"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db93bee9e027491aba19a6030c4c6437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316a25e3d35a45b78bef65e4e07c31b9",
              "IPY_MODEL_f3b7d45339b94f078a89290ac9da5607",
              "IPY_MODEL_b59b37c0ccd24e2ba77cb677242acded"
            ],
            "layout": "IPY_MODEL_9c666db811c74072956c34b49ab514a0"
          }
        },
        "316a25e3d35a45b78bef65e4e07c31b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f97ebe7f0a4a8dac082abec53fd2db",
            "placeholder": "​",
            "style": "IPY_MODEL_fea567cda0fd43469cfcc0cdf8d97a2f",
            "value": "Downloading fine_2.pt: 100%"
          }
        },
        "f3b7d45339b94f078a89290ac9da5607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5213e33c1ecc4273b3777ed3fbfe0980",
            "max": 3741740229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b5e8e1c227742f4b9ae7a98e0a0f836",
            "value": 3741740229
          }
        },
        "b59b37c0ccd24e2ba77cb677242acded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb656d962304aa6b6b1f491c227cb3f",
            "placeholder": "​",
            "style": "IPY_MODEL_fbb09c187b74426aa46d20f3a7ada9f6",
            "value": " 3.74G/3.74G [00:24&lt;00:00, 181MB/s]"
          }
        },
        "9c666db811c74072956c34b49ab514a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f97ebe7f0a4a8dac082abec53fd2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea567cda0fd43469cfcc0cdf8d97a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5213e33c1ecc4273b3777ed3fbfe0980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5e8e1c227742f4b9ae7a98e0a0f836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abb656d962304aa6b6b1f491c227cb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb09c187b74426aa46d20f3a7ada9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}